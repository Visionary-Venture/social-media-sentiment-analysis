{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "997c6085-4603-46ea-aeb9-9eacc82dc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the raw dataset\n",
    "df = pd.read_csv(\"../data/raw/Tweets.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45831aef-b44a-40ed-a81b-791e60dc98f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14427, 4)\n"
     ]
    }
   ],
   "source": [
    "# Keep only relevant columns\n",
    "df_clean = df[['text', 'airline_sentiment', 'airline', 'tweet_created']].copy()\n",
    "\n",
    "# Drop duplicates\n",
    "df_clean.drop_duplicates(subset='text', inplace=True)\n",
    "\n",
    "# Drop rows with missing text or sentiment\n",
    "df_clean.dropna(subset=['text', 'airline_sentiment'], inplace=True)\n",
    "\n",
    "print(df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e6390c3-512f-4090-83d7-be207ca1857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\saadu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>plus youve added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>didnt today must mean need take another trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0                @VirginAmerica What @dhepburn said.           neutral   \n",
       "1  @VirginAmerica plus you've added commercials t...          positive   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral   \n",
       "3  @VirginAmerica it's really aggressive to blast...          negative   \n",
       "4  @VirginAmerica and it's a really big bad thing...          negative   \n",
       "\n",
       "          airline              tweet_created  \\\n",
       "0  Virgin America  2015-02-24 11:35:52 -0800   \n",
       "1  Virgin America  2015-02-24 11:15:59 -0800   \n",
       "2  Virgin America  2015-02-24 11:15:48 -0800   \n",
       "3  Virgin America  2015-02-24 11:15:36 -0800   \n",
       "4  Virgin America  2015-02-24 11:14:45 -0800   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                               said  \n",
       "1      plus youve added commercials experience tacky  \n",
       "2       didnt today must mean need take another trip  \n",
       "3  really aggressive blast obnoxious entertainmen...  \n",
       "4                               really big bad thing  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)   # remove links\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)             # remove mentions\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)             # remove hashtags\n",
    "    text = re.sub(r\"[^A-Za-z\\s]\", \"\", text)      # remove punctuation/numbers\n",
    "    text = text.lower()                          # lowercase\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df_clean['clean_text'] = df_clean['text'].apply(clean_text)\n",
    "df_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5202c51f-7fe8-4d0d-9271-8f06e9618840",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "df_clean['sentiment_score'] = df_clean['airline_sentiment'].map(sentiment_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a012e78f-d433-447f-a9f9-3df9af2d0adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"../data/processed/tweets_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f6a31b8-0587-495f-b137-a4e645fc1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['clean_text'] = df_clean['text'].apply(clean_text)\n",
    "df_clean.to_csv(\"../data/processed/tweets_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3daec-25f8-4e9c-823c-570f6909a482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sma-venv)",
   "language": "python",
   "name": "sma-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
